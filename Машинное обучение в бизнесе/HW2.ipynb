{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa03d63d",
   "metadata": {},
   "source": [
    "### Задания\n",
    "1. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
    "2. Повторить п.2, но используя уже не медиану, а max\n",
    "3. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
    "4. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
    "5. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00faada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f144e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('./materials.csv')\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d540b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid                                        articles\n",
       "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
       "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
       "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('./users_articles.csv')\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3e6d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "stopword_ru = stopwords.words('russian')\n",
    "\n",
    "with open('./stopwords.txt', encoding='UTF-8') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines()]\n",
    "    \n",
    "stopword_ru += additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e760cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    text = text.lower()\n",
    "    test = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub('\\s+', ' ', re.sub('[\\d\\W\\^s-]+|\\t|\\n|\\s|\\r|n', ' ', text))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bdb43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    words = [w.text for w in list(tokenize(text))]\n",
    "    words_lem = []\n",
    "    \n",
    "    for w in words:\n",
    "        if w[0] == '-':\n",
    "            w = w[1:]\n",
    "        \n",
    "        if len(w) > 1:\n",
    "            if w in cache:\n",
    "                words_lem.append(cache[w])\n",
    "            else:\n",
    "                temp_cache = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cache)\n",
    "                \n",
    "    lemms_wo_stopwords = [w for w in words_lem if w not in stopword_ru]\n",
    "    \n",
    "    return lemms_wo_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228defb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11.6 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1b3beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 17s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a594540",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text for text in news['title']]\n",
    "\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a3898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(common_corpus, num_topics=22, id2word=common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161cad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: сша американский северный свидетельствовать украина россия санкция\n",
      "Topic 1: террорист виза боевик лесной римский взорваться уничтожить\n",
      "Topic 2: научный университет сша станция улица житель новый\n",
      "Topic 3: новый всё рынок рост система уровень американский\n",
      "Topic 4: статья км данные установить тысяча час рубль\n",
      "Topic 5: млрд рубль цена млн стоимость банк доход\n",
      "Topic 6: болезнь девочка di смерть завод фан куба\n",
      "Topic 7: мозг армия генерал форум операция территория ступень\n",
      "Topic 8: пенсия убийство наука мужчина район женщина испытание\n",
      "Topic 9: украина украинский российский санкция россия поток европа\n",
      "Topic 10: россия проект глава министр фонд развитие путин\n",
      "Topic 11: россия москва гражданин ребёнок территория российский женщина\n",
      "Topic 12: китай планета остров японский китайский иск космос\n",
      "Topic 13: снижение млн составить показатель тыс климат годовой\n",
      "Topic 14: население миссия эксперт журнал погибнуть эффективность вирус\n",
      "Topic 15: день хороший исследование всё первый мужчина большой\n",
      "Topic 16: исследование газ пациент лечение врач британский спрос\n",
      "Topic 17: банк решение власть правительство совет закон документ\n",
      "Topic 18: рейтинг место греция опрос подсчитать распространяться актёр\n",
      "Topic 19: взрыв специальный рак советский доля ссср дом\n",
      "Topic 20: всё журнал ребёнок смерть поверхность риск первый\n",
      "Topic 21: военный ракета россия наука земля первый технология\n"
     ]
    }
   ],
   "source": [
    "x = lda.show_topics(num_topics=22, num_words=7, formatted=False)\n",
    "topic_words = [(topic[0], [word[0] for word in topic[1]]) for topic in x]\n",
    "\n",
    "for topic, words in topic_words:\n",
    "    print(f'Topic {topic}: {\" \".join(words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23762e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_vector(text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "    \n",
    "    vector = []\n",
    "    for i in range(25):\n",
    "        if i not in not_null_topics:\n",
    "            vector.append(0)\n",
    "        else:\n",
    "            vector.append(not_null_topics[i])\n",
    "            \n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca99f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>topic_20</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134104</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>0.766913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.01829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  topic_0  topic_1   topic_2   topic_3  topic_4  topic_5  topic_6  \\\n",
       "0       6      0.0      0.0  0.000000  0.000000      0.0      0.0      0.0   \n",
       "1    4896      0.0      0.0  0.000000  0.000000      0.0      0.0      0.0   \n",
       "2    4897      0.0      0.0  0.089531  0.000000      0.0      0.0      0.0   \n",
       "3    4898      0.0      0.0  0.000000  0.533877      0.0      0.0      0.0   \n",
       "4    4899      0.0      0.0  0.000000  0.000000      0.0      0.0      0.0   \n",
       "\n",
       "    topic_7  topic_8  ...  topic_15  topic_16  topic_17  topic_18  topic_19  \\\n",
       "0  0.042864      0.0  ...  0.134104  0.011605  0.766913       0.0    0.0000   \n",
       "1  0.000000      0.0  ...  0.477775  0.000000  0.000000       0.0    0.4194   \n",
       "2  0.000000      0.0  ...  0.620792  0.000000  0.000000       0.0    0.0000   \n",
       "3  0.000000      0.0  ...  0.436695  0.000000  0.000000       0.0    0.0000   \n",
       "4  0.000000      0.0  ...  0.101799  0.000000  0.871472       0.0    0.0000   \n",
       "\n",
       "   topic_20  topic_21  topic_22  topic_23  topic_24  \n",
       "0   0.00000       0.0       0.0       0.0       0.0  \n",
       "1   0.00000       0.0       0.0       0.0       0.0  \n",
       "2   0.00000       0.0       0.0       0.0       0.0  \n",
       "3   0.01829       0.0       0.0       0.0       0.0  \n",
       "4   0.00000       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title']])\n",
    "topic_matrix.columns = [f'topic_{i}' for i in range(25)]\n",
    "topic_matrix.insert(0, 'doc_id', news['doc_id'].values)\n",
    "topic_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3ab455",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[[f'topic_{i}' for i in range(25)]].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc988c0",
   "metadata": {},
   "source": [
    "### Модели по среднему, медиане и максимуму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec2bdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>f-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc-auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amax</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        best_threshold  f-score  precision  recall  roc-auc\n",
       "mean              0.26     0.70       0.63    0.78     0.95\n",
       "median            0.33     0.80       0.84    0.76     0.98\n",
       "amax              0.36     0.79       0.77    0.80     0.97"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({}, columns=['best_threshold', 'f-score', 'precision', 'recall', 'roc-auc'])\n",
    "\n",
    "def get_user_embedding(user_articles_list, func):\n",
    "    user_articles_list = literal_eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    user_vector = func(user_vector, 0)\n",
    "    \n",
    "    return user_vector\n",
    "\n",
    "funcs = [np.mean, np.median, np.max]\n",
    "\n",
    "for func in funcs:\n",
    "\n",
    "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x, func), 1)])\n",
    "    user_embeddings.columns = [f'topic_{i}' for i in range(25)]\n",
    "    user_embeddings.insert(0, 'uid', users['uid'].values)\n",
    "\n",
    "    target = pd.read_csv(\"users_churn.csv\")\n",
    "    final = pd.merge(user_embeddings, target, 'left')\n",
    "\n",
    "    X = final[final.columns.difference(['churn', 'uid'])]\n",
    "    y = final['churn']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    logr = LogisticRegression()\n",
    "    logr.fit(X_train, y_train)\n",
    "\n",
    "    preds = logr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    ix = np.argmax(fscore)\n",
    "\n",
    "    metrics = list(map(lambda x: round(x, 2), \n",
    "                       [thresholds[ix], fscore[ix], precision[ix], recall[ix], roc_auc_score(y_test, preds)]))\n",
    "    \n",
    "    result.loc[func.__name__] = metrics\n",
    "    \n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
